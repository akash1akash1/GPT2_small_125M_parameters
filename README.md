# GPT2_small_125M_parameters
GPT2_small_125M_parameters model training in multiple GPU.

Run the colab file fsdp-training.ipynb it uses multiple GPUs this code is te training.

Run the colab file gpt2-from-scratch.ipynb it is the architecture of gpt-2 as well as i have validated the implementation by loading the original GPT-2 125M model checkpoints and ran a sample prediction 

run gpt2-modified-architecture.ipynb , this is the modified gpt where we used grouped query attention mechanism 

..
To check the working of chatbot run app.py 
